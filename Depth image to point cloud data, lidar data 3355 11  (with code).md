#  I. Introduction 

>  There are many ways to obtain depth images, such as lidar, structured light, and depth cameras. Many tutorials on the Internet explain the conversion of depth images acquired by depth cameras into 3D point cloud data (camera internal and external parameters), but the depth cameras generated by lidar are usually different from those generated by cameras. For details, please refer to the following figure: 

![avatar]( f7df58f37a574f21a66c8b0e0bc090fa.png) 

>  As shown in the figure above, in the depth image generated by the laser point cloud data, the brightness value of each pixel represents the distance value from the object to the scanner. The pitch angle of each row is the same, and the yaw angle of each column is the same. Therefore, such a depth image represents each point in the point cloud through the depth value, pitch angle and yaw angle. This is mainly because the process of generating depth images through laser point cloud data is actually a sampling process, as shown in the figure below. 

          O 

         O 

     O represents the position of the laser scanner, which is sampled by equal pitch horizontal and vertical rotation viewing angles. If there is a point in this viewing angle, record its distance value as the luminance value of the pixel, and record the pitch angle and yaw angle at this time at the same time. Otherwise, it is recorded as 0. Then the depth image can be converted into the original point cloud data in reverse through these three, of course, there are still errors in the process. 

![avatar]( 9b7c37c0ff354de1b38c0caabea9b180.png) 

>  According to the above figure, let 

          O 

          P 

         OP 

     The distance of the OP is 

          D 

         D 

     D, the specific point cloud coordinate formula is: 

#  Code implementation 

We take the open source dataset (https://rosbag.tier4.jp/) as an example, obtain a depth image in the dataset, and we restore it. 

>  AngleToRad.m 

 ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 202402030957405455
 ```  
>  RangeImageToPointCloud.m 

 ```python  
After clicking on the GitHub Sponsor button above, you will obtain access permissions to my private code repository ( https://github.com/slowlon/my_code_bar ) to view this blog code. By searching the code number of this blog, you can find the code you need, code number is: 202402030957405455
 ```  
#  III. Achieving results 

>  Original data source 

![avatar]( f6147410a182425094d6dab3d2eb57b4.png) 

>  Transformed point cloud data 

![avatar]( ffe789c95aac41f58e2da32279b958f8.png) 

![avatar]( 165d14a51781405ebfa40acbc153ae81.png) 

#  References 

>  [1] Real-Time Streaming Point Cloud Compression for 3D LiDAR Sensor Using U-Net [2] Acquisition and Processing of Depth Image 

